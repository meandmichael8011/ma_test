{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQHIuKajiQl0"
   },
   "source": [
    "## Тестовое задание MA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpB3LWyMiVm7"
   },
   "source": [
    "Добрый день! В этом ноутбуке содержится моё тестовое задание в компанию MA.\n",
    "- Трейнинг и оценка модели выполнены в фреймворке TensorFlow / Keras.\n",
    "- Модель, которая была натренирована на данных, - это Xception (https://arxiv.org/abs/1610.02357). Причина моего выбора лежит в том, что изображения, на которых мне предстояло тренировать модель, были немного шумными, с достаточно небольшой яркостью, временами - некоторым перекосом. В связи с этим, я решил выбрать более \"глубокую\" структуру Xception, так как основной особенностью этой модели (и предшествующей ей Inception v3) является разветвлённая архитектура, позволяющая модели проводить конволюцию и изучать свойства изображений на разных каналах. Эта модель является более глубокой и сложной, с бо́льшим количеством параметров - в целом это хороший выбор для сложных изображений и, хотя в данной ситуации я мог обойтись простой моделью с парой Conv2D-слоёв, я предпочёл использовать более сложную модель с аугментацией данных для борьбы с переобучением.\n",
    "- Результаты обучения и тестов Вы можете видеть в конце данного ноутбука.\n",
    "- Для более наглядной оценки я также сделал:\n",
    "1) Простой пользовательский интерфейс в Gradio, где Вы можете проверить мою модель на реальных данных. Ссылка:\n",
    "2) PDF-отчёт, где представлены линии обучения и результаты в виде графика (его можно найти в репозитории на GitHub и HuggingFace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNwdSZboidZq"
   },
   "source": [
    "Структура выполнения задачи:\n",
    "\n",
    "- Импорт датасетов\n",
    "- Импорт изображений с помощью ImageDataGenerator, использовать аугментацию данных. Убедиться, что тестовые изображения отделены от тренировочных для недопущения утечки (все названия трейн / валид изображений есть в датасетах)\n",
    "- Определение модели (из кандидатов: Xception, Regular CNN, YOLOv11m, MobileNetv2), при выборе сложной модели добавить Residual Connections. Конечная задача - мультиклассовый лейбелинг (лосс - категорическая кросс-энтропия)\n",
    "- Тренировка модели, тюнинг параметров (при наличии тюнабельных)\n",
    "- Тест модели, оценка результатов (acc, precision, recall)\n",
    "- Публикация на ГитХаб и HuggingFace с созданием UI в Gradio. Требования для UI: возможность напрямую загрузить изображения, нажать кнопку для инференса, поле для выдачи результата\n",
    "- Мини-отчёт, PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP-ctBo3iuWa"
   },
   "source": [
    "## Импорт библиотек и датасетов, обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для удобства установки библиотек воспользуйтесь этой командой в терминале:\n",
    "### !pip install pandas tensorflow numpy scipy opencv-python\n",
    "### Пожалуйста не обращайте внимания на предупреждения - я делаю этот проект на свежей версии Ubuntu без CUDA-драйверов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F-lpYkUdit4b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 20:46:28.358019: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-05 20:46:28.363274: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-05 20:46:28.415384: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-05 20:46:28.461322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738781188.507000    5844 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738781188.519514    5844 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-05 20:46:28.618734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation  \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat = pd.read_csv(\"test.csv\").sort_values(by=['img_name'], ascending=True)\n",
    "check_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для проверки на тест-сете\n",
    "### Функция для инференса на новых изображениях\n",
    "def check_new(image_path):\n",
    "    ### Импорт модели\n",
    "    model = tf.keras.models.load_model('xception_trained.keras')\n",
    "    check_img = cv2.imread(image_path)\n",
    "    check_img = cv2.cvtColor(check_img, cv2.COLOR_BGR2RGB)  \n",
    "    check_img2 = cv2.resize(check_img, (71, 71)) / 255.0\n",
    "    check_img2 = np.expand_dims(check_img2, axis=0)\n",
    "    pred = model.predict(check_img2)\n",
    "    pred_indices = np.argmax(pred, axis=-1)[0]  \n",
    "    digits = []\n",
    "    for idx in pred_indices:\n",
    "        if idx == 10:\n",
    "            break\n",
    "        digits.append(str(idx))\n",
    "    if digits:\n",
    "        final_number = \"\".join(digits)  \n",
    "    else: \n",
    "        final_number = \"\"\n",
    "    #save_path = f'results/{str(final_number)}.jpeg'  \n",
    "    #cv2.imwrite(save_path, check_img) \n",
    "    return(final_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in test_dat['img_name']:\n",
    "    f1 = check_new(\"imgs/\" + num)\n",
    "    f2 = str(num + \"  -  \" + f1)\n",
    "    check_list.append(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['481896362_2.jpg  -  499',\n",
       " '481896530_2.jpg  -  289',\n",
       " '481896607_2.jpg  -  219',\n",
       " '481896633_2.jpg  -  1099',\n",
       " '481896722_2.jpg  -  799',\n",
       " '481896746_2.jpg  -  899',\n",
       " '481896751_2.jpg  -  189',\n",
       " '481896850_2.jpg  -  649',\n",
       " '481896944_2.jpg  -  109',\n",
       " '481897078_2.jpg  -  549',\n",
       " '481897094_2.jpg  -  899',\n",
       " '481897095_2.jpg  -  899',\n",
       " '481897151_2.jpg  -  499',\n",
       " '483317915_2.jpg  -  949',\n",
       " '483319459_2.jpg  -  71',\n",
       " '483319541_2.jpg  -  95',\n",
       " '483319571_2.jpg  -  159',\n",
       " '483319576_2.jpg  -  149',\n",
       " '483319625_2.jpg  -  109',\n",
       " '483319731_2.jpg  -  139',\n",
       " '483319792_2.jpg  -  119',\n",
       " '483319825_2.jpg  -  119',\n",
       " '483319826_2.jpg  -  189',\n",
       " '483319836_2.jpg  -  149',\n",
       " '487494940_2.jpg  -  599',\n",
       " '487494957_2.jpg  -  659',\n",
       " '487494964_2.jpg  -  419',\n",
       " '487494977_2.jpg  -  649',\n",
       " '487495055_2.jpg  -  2699',\n",
       " '487495274_2.jpg  -  859',\n",
       " '487495463_2.jpg  -  439',\n",
       " '487495495_2.jpg  -  1899',\n",
       " '487495522_2.jpg  -  469',\n",
       " '487495634_2.jpg  -  469',\n",
       " '508748981_2.jpg  -  109',\n",
       " '508754093_2.jpg  -  54',\n",
       " '508754157_2.jpg  -  124',\n",
       " '508757462_2.jpg  -  519',\n",
       " '508757585_2.jpg  -  32',\n",
       " '508757587_2.jpg  -  26',\n",
       " '508757691_2.jpg  -  41',\n",
       " '508758064_2.jpg  -  63',\n",
       " '508758082_2.jpg  -  45',\n",
       " '508758295_2.jpg  -  122',\n",
       " '508758340_2.jpg  -  21',\n",
       " '508758452_2.jpg  -  269',\n",
       " '508758609_2.jpg  -  259',\n",
       " '508758615_2.jpg  -  259',\n",
       " '508758621_2.jpg  -  259',\n",
       " '508758627_2.jpg  -  219',\n",
       " '508758641_2.jpg  -  71',\n",
       " '508758670_2.jpg  -  82',\n",
       " '508759251_2.jpg  -  399',\n",
       " '508759568_2.jpg  -  1449',\n",
       " '508759769_2.jpg  -  4999',\n",
       " '508759782_2.jpg  -  229',\n",
       " '508760058_2.jpg  -  769',\n",
       " '508760326_2.jpg  -  299',\n",
       " '508760507_2.jpg  -  379',\n",
       " '508760637_2.jpg  -  289',\n",
       " '508760899_2.jpg  -  143',\n",
       " '508761063_2.jpg  -  89',\n",
       " '508761090_2.jpg  -  149',\n",
       " '508761152_2.jpg  -  101',\n",
       " '508761254_2.jpg  -  103',\n",
       " '508761466_2.jpg  -  44',\n",
       " '508761616_2.jpg  -  55',\n",
       " '508761836_2.jpg  -  559',\n",
       " '508761874_2.jpg  -  15',\n",
       " '508762084_2.jpg  -  86',\n",
       " '508762091_2.jpg  -  69',\n",
       " '508762097_2.jpg  -  69',\n",
       " '508762181_2.jpg  -  179',\n",
       " '508762247_2.jpg  -  269',\n",
       " '508762297_2.jpg  -  89',\n",
       " '508762298_2.jpg  -  79',\n",
       " '508762567_2.jpg  -  89',\n",
       " '508762714_2.jpg  -  79',\n",
       " '508762768_2.jpg  -  2199',\n",
       " '508762957_2.jpg  -  24',\n",
       " '508763059_2.jpg  -  119',\n",
       " '508763144_2.jpg  -  89',\n",
       " '508763314_2.jpg  -  179',\n",
       " '508763321_2.jpg  -  149',\n",
       " '508763356_2.jpg  -  59',\n",
       " '508763392_2.jpg  -  79',\n",
       " '508763557_2.jpg  -  599',\n",
       " '508763562_2.jpg  -  539',\n",
       " '508763565_2.jpg  -  549',\n",
       " '508763602_2.jpg  -  609',\n",
       " '508763650_2.jpg  -  37',\n",
       " '508763873_2.jpg  -  199',\n",
       " '508763941_2.jpg  -  57',\n",
       " '508764198_2.jpg  -  1999',\n",
       " '508764201_2.jpg  -  1999',\n",
       " '508764288_2.jpg  -  93',\n",
       " '508764417_2.jpg  -  1039',\n",
       " '508764973_2.jpg  -  24',\n",
       " '508764988_2.jpg  -  169',\n",
       " '508765269_2.jpg  -  60',\n",
       " '508765282_2.jpg  -  36',\n",
       " '508765556_2.jpg  -  269',\n",
       " '508765637_2.jpg  -  93',\n",
       " '508765807_2.jpg  -  649',\n",
       " '508766128_2.jpg  -  199',\n",
       " '508775211_2.jpg  -  62',\n",
       " '508775221_2.jpg  -  45',\n",
       " '508775231_2.jpg  -  142',\n",
       " '508775582_2.jpg  -  999',\n",
       " '508776052_2.jpg  -  39',\n",
       " '508776274_2.jpg  -  209',\n",
       " '508776278_2.jpg  -  239',\n",
       " '508776595_2.jpg  -  189',\n",
       " '508776602_2.jpg  -  159',\n",
       " '508777432_2.jpg  -  209',\n",
       " '508777443_2.jpg  -  204',\n",
       " '508777873_2.jpg  -  106',\n",
       " '508777893_2.jpg  -  219',\n",
       " '508778533_2.jpg  -  99',\n",
       " '508780362_2.jpg  -  139',\n",
       " '508780483_2.jpg  -  439',\n",
       " '508780913_2.jpg  -  459',\n",
       " '508780958_2.jpg  -  109',\n",
       " '508780966_2.jpg  -  52',\n",
       " '508782301_2.jpg  -  69',\n",
       " '508782432_2.jpg  -  899',\n",
       " '508782448_2.jpg  -  82',\n",
       " '508782808_2.jpg  -  299',\n",
       " '508782897_2.jpg  -  664',\n",
       " '508783284_2.jpg  -  149',\n",
       " '508783317_2.jpg  -  24',\n",
       " '508784193_2.jpg  -  899',\n",
       " '508784219_2.jpg  -  599',\n",
       " '508784229_2.jpg  -  279',\n",
       " '508784243_2.jpg  -  259',\n",
       " '508785263_2.jpg  -  289',\n",
       " '508785548_2.jpg  -  519',\n",
       " '508785742_2.jpg  -  88',\n",
       " '508793962_2.jpg  -  479',\n",
       " '508795840_2.jpg  -  124',\n",
       " '508795857_2.jpg  -  132',\n",
       " '508800012_2.jpg  -  379',\n",
       " '508800035_2.jpg  -  379',\n",
       " '508811823_2.jpg  -  139',\n",
       " '508812636_2.jpg  -  69',\n",
       " '508813287_2.jpg  -  1699',\n",
       " '508813357_2.jpg  -  399',\n",
       " '508957589_2.jpg  -  16',\n",
       " '508968126_2.jpg  -  89',\n",
       " '509199267_2.jpg  -  559',\n",
       " '509211393_2.jpg  -  169',\n",
       " '509233416_2.jpg  -  119',\n",
       " '509267326_2.jpg  -  269',\n",
       " '509317303_2.jpg  -  66',\n",
       " '509317306_2.jpg  -  129',\n",
       " '509323395_2.jpg  -  289',\n",
       " '509332023_2.jpg  -  149',\n",
       " '509390357_2.jpg  -  109',\n",
       " '509390583_2.jpg  -  109',\n",
       " '509390607_2.jpg  -  219',\n",
       " '509494172_2.jpg  -  49',\n",
       " '509496992_2.jpg  -  42',\n",
       " '509513094_2.jpg  -  82',\n",
       " '509520206_2.jpg  -  149',\n",
       " '509664347_2.jpg  -  439',\n",
       " '509664354_2.jpg  -  519',\n",
       " '509664356_2.jpg  -  569',\n",
       " '509664402_2.jpg  -  259',\n",
       " '509681182_2.jpg  -  569',\n",
       " '509702502_2.jpg  -  749',\n",
       " '509702506_2.jpg  -  529',\n",
       " '509714006_2.jpg  -  149',\n",
       " '509714115_2.jpg  -  32',\n",
       " '510831243_2.jpg  -  819',\n",
       " '510831357_2.jpg  -  509',\n",
       " '510831360_2.jpg  -  299',\n",
       " '510831481_2.jpg  -  409',\n",
       " '510831498_2.jpg  -  549',\n",
       " '510831842_2.jpg  -  139',\n",
       " '510832112_2.jpg  -  89',\n",
       " '510832160_2.jpg  -  115',\n",
       " '510833949_2.jpg  -  95',\n",
       " '510879735_2.jpg  -  1299',\n",
       " '510879764_2.jpg  -  119',\n",
       " '510879766_2.jpg  -  439',\n",
       " '510879791_2.jpg  -  249',\n",
       " '510879859_2.jpg  -  209',\n",
       " '510879877_2.jpg  -  619',\n",
       " '510879879_2.jpg  -  249',\n",
       " '510879966_2.jpg  -  229',\n",
       " '510879999_2.jpg  -  259',\n",
       " '510880062_2.jpg  -  119',\n",
       " '510880067_2.jpg  -  109',\n",
       " '510880074_2.jpg  -  199',\n",
       " '510883351_2.jpg  -  69',\n",
       " '510883372_2.jpg  -  469',\n",
       " '510883403_2.jpg  -  249',\n",
       " '510883406_2.jpg  -  599',\n",
       " '510883515_2.jpg  -  75',\n",
       " '510883758_2.jpg  -  199',\n",
       " '510883776_2.jpg  -  109',\n",
       " '510884290_2.jpg  -  109',\n",
       " '510884341_2.jpg  -  199',\n",
       " '510884347_2.jpg  -  799',\n",
       " '510884783_2.jpg  -  54',\n",
       " '510885566_2.jpg  -  104',\n",
       " '510885631_2.jpg  -  139',\n",
       " '510885909_2.jpg  -  44',\n",
       " '510885928_2.jpg  -  79',\n",
       " '510885952_2.jpg  -  199',\n",
       " '510885953_2.jpg  -  144',\n",
       " '510933302_2.jpg  -  208',\n",
       " '510947685_2.jpg  -  59',\n",
       " '511017499_2.jpg  -  11',\n",
       " '511027111_2.jpg  -  11',\n",
       " '511132603_2.jpg  -  43',\n",
       " '511193297_2.jpg  -  399',\n",
       " '511200975_2.jpg  -  45',\n",
       " '511200976_2.jpg  -  45',\n",
       " '511220120_2.jpg  -  99',\n",
       " '511224018_2.jpg  -  159',\n",
       " '511225281_2.jpg  -  49',\n",
       " '511228291_2.jpg  -  71',\n",
       " '511228497_2.jpg  -  144',\n",
       " '511232991_2.jpg  -  67',\n",
       " '511233287_2.jpg  -  259',\n",
       " '511233291_2.jpg  -  519',\n",
       " '511237915_2.jpg  -  529',\n",
       " '511237935_2.jpg  -  439',\n",
       " '511259241_2.jpg  -  219',\n",
       " '511263698_2.jpg  -  499',\n",
       " '511266341_2.jpg  -  199',\n",
       " '511266390_2.jpg  -  799',\n",
       " '511266402_2.jpg  -  119',\n",
       " '511266403_2.jpg  -  69',\n",
       " '511270506_2.jpg  -  224',\n",
       " '511270808_2.jpg  -  199',\n",
       " '511277610_2.jpg  -  239']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Список, в котором зафиксированы все результаты модели\n",
    "check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Здесь Вы можете проверить модель на новом изображении. Запустите эту ячейку, вставьте путь до изображения \n",
    "### и проверьте полученный вывод. Внутри этой функции прописан импорт последней лучшей модели, пожалуйста\n",
    "### убедитесь, что модель находится в той же директории, где был этот ноутбук.\n",
    "path = input(\"Пожалуйста вставьте путь до изображения: \")\n",
    "check_new(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bvgzhxn3lrfD"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Здесь я создам плейсхолдер для тренировки, чтобы затем на эти списки прикрепить тензоры изображений и их ярлыки.\n",
    "img_train = []\n",
    "lab_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "TAG-_OnKqPvc",
    "outputId": "b8cfac7b-5783-4134-ee21-bc3ee7504f5b"
   },
   "outputs": [],
   "source": [
    "### Загружаю изображения, заранее меняя их размер на 71х71, т.к. это самый \"съедобный\" формат для Xception\n",
    "for index, row in train_df.iterrows():\n",
    "  name = row['img_name']\n",
    "  text = row['text']\n",
    "  img = cv2.imread(\"imgs/\" + name)\n",
    "  img2 = cv2.resize(img, (71, 71)) / 255.0\n",
    "  label = int(text)\n",
    "  digits = [int(d) for d in str(label)]\n",
    "  img_train.append(img2)\n",
    "  lab_train.append(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Этот плейсхолдер также для тренировки, но уже для аугментированных изображений из трейн-датасета. \n",
    "### Поскольку Xception - это модель со сложной архитектурой, без аугментации данных мы бы быстро переобучились\n",
    "img_train_aug = []\n",
    "lab_train_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для более удобной аугментации я создам функцию, которая принимает два пустых списка и два Series-объекта,\n",
    "### в которых уже заготовлены тензоры изображения и ярлыки. Полученные результаты аппендятся на списки\n",
    "### с окончанием \"aug\". \n",
    "def augment(images_to_augment, labels_to_augment, list_img, list_lab):\n",
    "    datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest') ### Ряд аугментаций, которые будут применяться, среди которых урезка, зум, флип и др.\n",
    "\n",
    "    for i, (image, label) in enumerate(zip(images_to_augment, labels_to_augment)):\n",
    "        ### Применяем аугментацию. Для самопроверки пришлось несколько раз делать ресайз.\n",
    "        augmented_image = datagen.random_transform(image)  # Augment the image\n",
    "        augmented_image = augmented_image * 255.0  # Scale the values back\n",
    "        augmented_image = np.clip(augmented_image, 0, 255).astype('uint8')  # Clip values to 0-255 range\n",
    "        \n",
    "        ### Для проверки, что аугментация правильно работает\n",
    "        #save_path = f'aug/aug_{i}.jpeg'  \n",
    "        #cv2.imwrite(save_path, augmented_image)  \n",
    "        \n",
    "        ### Аппенд на пустые списки\n",
    "        img_normalized = augmented_image.astype('float32') / 255.0 \n",
    "        list_img.append(img_normalized)\n",
    "        list_lab.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment(img_train, lab_train, img_train_aug, lab_train_aug) ### Применяем функцию на трейн сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Получаем полноценные, аугментированные трейн-изображения и ярлыки\n",
    "X_train = np.array(np.concatenate([img_train, img_train_aug]), dtype=np.float32) \n",
    "max_label_length = max(len(label) for label in lab_train)  ### Нужен паддинг ярлыков, модель принимает только послед. одинакового размера\n",
    "y_train_n_padded = pad_sequences(lab_train, maxlen=max_label_length, padding='post', value=-1)\n",
    "y_train_aug_padded = pad_sequences(lab_train_aug, maxlen=max_label_length, padding='post', value=-1) ### Паддинг устанавливаем в конце\n",
    "y_train = np.concatenate([y_train_n_padded, y_train_aug_padded]) ### Получаем полноценный список ярлыков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Все те же самые операции проводим на валидационном сете. Нужно чтобы градиентный спуск работал от как можно более\n",
    "### репрезентативной выборки с разнообразными изображениями ценников.\n",
    "img_val = []\n",
    "lab_val = []\n",
    "img_val_aug = []\n",
    "lab_val_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in val_df.iterrows():\n",
    "  name = row['img_name']\n",
    "  text = row['text']\n",
    "  img = cv2.imread(\"imgs/\" + name)\n",
    "  img2 = cv2.resize(img, (71, 71)) / 255.0\n",
    "  label = int(text)\n",
    "  digits = [int(d) for d in str(label)]\n",
    "  img_val.append(img2)\n",
    "  lab_val.append(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment(img_val, lab_val, img_val_aug, lab_val_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(np.concatenate([img_val, img_val_aug]), dtype=np.float32) \n",
    "max_label_length1 = max(len(label) for label in lab_train)  # Find the longest sequence\n",
    "y_val_n_padded = pad_sequences(lab_val, maxlen=max_label_length1, padding='post', value=-1)\n",
    "y_val_aug_padded = pad_sequences(lab_val_aug, maxlen=max_label_length1, padding='post', value=-1)\n",
    "y_val = np.concatenate([y_val_n_padded, y_val_aug_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Устанавливаем кол-во классов на 11, так как помимо 10 цифр (0-9) также остаётся нейрон для паддинга.\n",
    "### Проводим one-hot encoding для ярлыков (т.к. задача заключается в классификации).\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "num_classes = 11 \n",
    "y_train_onehot = np.array([to_categorical(label, num_classes=num_classes) for label in y_train])\n",
    "y_val_onehot = np.array([to_categorical(label, num_classes=num_classes) for label in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### К сожалению, эту часть пришлось отыскать на StackOverflow и адапьировать под мой код, т.к. в моей ситуации ярлыки \n",
    "### состояли из 4-х разных векторов, и просто использовать стандартные метрики точности-полноты из Тензорфлоу не получлиось бы.\n",
    "class fl_precision(Precision):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "\n",
    "        y_true = tf.reshape(y_true, (-1, y_true.shape[-1]))  \n",
    "        y_pred = tf.reshape(y_pred, (-1, y_pred.shape[-1]))  \n",
    "        y_true = tf.argmax(y_true, axis=-1)  \n",
    "        y_pred = tf.argmax(y_pred, axis=-1)  \n",
    "\n",
    "        super().update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "class fl_recall(Recall):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (-1, y_true.shape[-1]))  \n",
    "        y_pred = tf.reshape(y_pred, (-1, y_pred.shape[-1]))  \n",
    "\n",
    "        y_true = tf.argmax(y_true, axis=-1)  \n",
    "        y_pred = tf.argmax(y_pred, axis=-1)  \n",
    "\n",
    "        super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5906 - fl_precision_2: 0.9848 - fl_recall_2: 0.9894 - loss: 1.2088 - val_accuracy: 0.4280 - val_fl_precision_2: 0.9808 - val_fl_recall_2: 1.0000 - val_loss: 2.0986\n",
      "Epoch 2/5\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 979ms/step - accuracy: 0.8600 - fl_precision_2: 0.9950 - fl_recall_2: 0.9949 - loss: 0.4333 - val_accuracy: 0.5185 - val_fl_precision_2: 0.9808 - val_fl_recall_2: 1.0000 - val_loss: 1.7661\n",
      "Epoch 3/5\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.9233 - fl_precision_2: 0.9974 - fl_recall_2: 0.9982 - loss: 0.2335 - val_accuracy: 0.7423 - val_fl_precision_2: 0.9885 - val_fl_recall_2: 1.0000 - val_loss: 0.8710\n",
      "Epoch 4/5\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.9522 - fl_precision_2: 0.9985 - fl_recall_2: 0.9980 - loss: 0.1438 - val_accuracy: 0.9215 - val_fl_precision_2: 0.9986 - val_fl_recall_2: 0.9963 - val_loss: 0.2749\n",
      "Epoch 5/5\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.9638 - fl_precision_2: 0.9985 - fl_recall_2: 0.9987 - loss: 0.1141 - val_accuracy: 0.9233 - val_fl_precision_2: 0.9944 - val_fl_recall_2: 0.9999 - val_loss: 0.2798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d7682be63f0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Определяем модель. Помимо Xception, я также попробовал некоторые другие архитектуры - к примеру, MobileNetv2, простую\n",
    "### CNN-ку и, ради эксперимента, Xception + residual connections. Как я убедился, в итоге Xception всё равно побеждает по \n",
    "### val_accuracy и val_loss, поэтому решено остаться на этой модели. Для тренировки использую Keras API\n",
    "\n",
    "\n",
    "metrics = ['accuracy', fl_precision(), fl_recall()]\n",
    "### Убираем классификатор и претрейн, чтобы натренировать модель с нуля. Загружаем только бэкбоун модели, определяем \n",
    "### форму входных данных (71х71, как было раньше установлено).\n",
    "base = Xception(weights=None, include_top=False, input_shape=(71, 71, 3)) \n",
    "\n",
    "### Используем пулинг для того, чтобы уменьшить фича-мапы и оставить только самые нужные активации\n",
    "### Так как каждый ярлык состоит из 4-х one-hot векторов, все размером 11, нам нужен аутпут в 44 нейрона.\n",
    "x = GlobalAveragePooling2D()(base.output)  # Output shape: (batch_size, 2048)\n",
    "x = Dense(4 * 11)(x)\n",
    "x = Reshape((4, 11))(x)\n",
    "outputs = Activation('softmax')(x) ### Функция активации выходных данных - Софтмакс, т.к. мы рассматриваем распределение вероятностей.\n",
    "model = Model(inputs=base.input, outputs=outputs) ### Аутпут в форме логитов\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics) ### Лосс - категорическая кросс-энтропия\n",
    "\n",
    "### Возможно было использовать EarlyStopping со стратегией на валидационную точность, но т.к. я трейнил модели несколько раз, то \n",
    "### эмпирическим путём я убедился, что после 5 эпох точность не повышается, либо же модель начинает оверфиттить. \n",
    "### Из-за последнего я также слегка повысил бэтч сайз, чтобы обновления параметров модели не были слишком тщательными.\n",
    "model.fit(X_train, y_train_onehot, epochs=5, batch_size=64, validation_data=(X_val, y_val_onehot)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xception_trained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Функция для инференса на новых изображениях\n",
    "def check_new(image_path):\n",
    "    ### Импорт модели\n",
    "    model = tf.keras.models.load_model('models/xception_trained.keras')\n",
    "    check_img = cv2.imread(image_path)\n",
    "    check_img = cv2.cvtColor(check_img, cv2.COLOR_BGR2RGB)  \n",
    "    check_img2 = cv2.resize(check_img, (71, 71)) / 255.0\n",
    "    check_img2 = np.expand_dims(check_img2, axis=0)\n",
    "    pred = model.predict(check_img2)\n",
    "    pred_indices = np.argmax(pred, axis=-1)[0]  \n",
    "    digits = []\n",
    "    for idx in pred_indices:\n",
    "        if idx == 10:\n",
    "            break\n",
    "        digits.append(str(idx))\n",
    "    if digits:\n",
    "        final_number = \"\".join(digits)  \n",
    "    else: \n",
    "        final_number = \"\"\n",
    "    print(final_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Пожалуйста вставьте путь до изображения:  imgs/511270808_2.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "### Здесь Вы можете проверить модель на новом изображении. Запустите эту ячейку, вставьте путь до изображения \n",
    "### и проверьте полученный вывод. Внутри этой функции прописан импорт последней лучшей модели, пожалуйста\n",
    "### убедитесь, что модель находится в той же директории, где был этот ноутбук. Спасибо за внимание :)\n",
    "path = input(\"Пожалуйста вставьте путь до изображения: \")\n",
    "check_new(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
